{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f58c70f-17df-4dd2-a997-402ff101134b",
   "metadata": {},
   "source": [
    "# A Benchmark comparing mercury.dynamics.settrie and the python implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263aeea-8336-49f3-975a-58b93af96488",
   "metadata": {},
   "source": [
    "We import some python utils for timing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e944525-d80a-4684-b635-1d1eb346b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b1e02-cd49-43fb-8384-f80de7c497c3",
   "metadata": {},
   "source": [
    "We import the class `SetTrieMap()` the python implementation of settrie that can be found at https://github.com/mmihaltz/pysettrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ba45e6-b3f6-4b6c-a95f-45bbb4f07bf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Set-trie-based associative array. TODO: Redo doc and ask Oscar source code origin\"\"\"\n",
    "import sys\n",
    "import sortedcontainers\n",
    "\n",
    "\n",
    "class SetTrieMap:\n",
    "    \"\"\"Associative array where keys are sets.\n",
    "\n",
    "    Mapping container for efficient storage of key-value pairs where\n",
    "    the keys are sets. Uses an efficient trie implementation. Supports querying\n",
    "    for values associated to subsets or supersets of stored key sets.\n",
    "\n",
    "    Examples:\n",
    "    >>> from settrie import SetTrieMap\n",
    "    ... m = SetTrieMap()\n",
    "    ... m.assign({1,2}, 'A')\n",
    "    ... m.assign({1,2,3}, 'B')\n",
    "    ... m.assign({2,3,5}, 'C')\n",
    "    ... m\n",
    "    [({1, 2}, 'A'), ({1, 2, 3}, 'B'), ({2, 3, 5}, 'C')]\n",
    "    >>> m.get({1,2,3})\n",
    "    'B'\n",
    "    >>> m.get({1, 2, 3, 4}, 'Nope!')\n",
    "    'Nope!'\n",
    "    >>> list(m.keys())\n",
    "    [{1, 2}, {1, 2, 3}, {2, 3, 5}]\n",
    "    >>> m.supersets( {1,2} )\n",
    "    [({1, 2}, 'A'), ({1, 2, 3}, 'B')]\n",
    "    >>> m.supersets({1, 2}, mode='keys')\n",
    "    [{1, 2}, {1, 2, 3}]\n",
    "    >>> m.supersets({1, 2}, mode='values')\n",
    "    ['A', 'B']\n",
    "    \"\"\"\n",
    "\n",
    "    class Node:\n",
    "        \"\"\"Node object used by SetTrieMap.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, data=None, trie=None):\n",
    "            # child nodes a.k.a. children\n",
    "            self.children = sortedcontainers.SortedList()\n",
    "            # flag_last: if True, this is the last element of a key set store a\n",
    "            # member element of the key set. Must be a hashable\n",
    "            # (i.e. hash(data) should work), that makes it comparable/orderable\n",
    "            # (i.e. data1 < data2 should work; see\n",
    "            # https://wiki.python.org/moin/HowTo/Sorting/) type.\n",
    "            self.flag_last = False\n",
    "            self.data = data\n",
    "            self.data_hash = trie.idx_func(data)\n",
    "            # the value associated to the key set if flag_last == True,\n",
    "            # otherwise None\n",
    "            self.value = None\n",
    "\n",
    "        # comparison operators to support rich comparisons, sorting\n",
    "        # etc. using self.data as key\n",
    "        def __eq__(self, other):\n",
    "            return self.data_hash == other.data_hash\n",
    "\n",
    "        def __ne__(self, other):\n",
    "            return self.data_hash != other.data_hash\n",
    "\n",
    "        def __lt__(self, other):\n",
    "            return self.data_hash < other.data_hash\n",
    "\n",
    "        def __le__(self, other):\n",
    "            return self.data_hash <= other.data_hash\n",
    "\n",
    "        def __gt__(self, other):\n",
    "            return self.data_hash > other.data_hash\n",
    "\n",
    "        def __ge__(self, other):\n",
    "            return self.data_hash >= other.data_hash\n",
    "\n",
    "    def __init__(self, iterable=None, idx_func=None):\n",
    "        \"\"\"Set up this SetTrieMap object.  If iterable is specified, it must\n",
    "           be an iterable of (keyset, value) pairs from which set-trie\n",
    "           is populated.\n",
    "        \"\"\"\n",
    "        self.idx_func = idx_func if idx_func else hash\n",
    "        self.root = SetTrieMap.Node(trie=self)\n",
    "\n",
    "        if iterable is not None:\n",
    "            for key, value in iterable:\n",
    "                self.assign(key, value)\n",
    "\n",
    "    def assign(self, akey, avalue):\n",
    "        \"\"\"Add key akey with associated value avalue to the container.\n",
    "           akey must be a sortable and iterable container type.\"\"\"\n",
    "        self._assign(self.root, iter(sorted(akey, key=self.idx_func)), avalue)\n",
    "\n",
    "    def _assign(self, node, it, val):\n",
    "        \"\"\"Recursive function used by self.assign().\"\"\"\n",
    "        try:\n",
    "            data = next(it)\n",
    "            nextnode = None\n",
    "            try:\n",
    "                # find first child with this data\n",
    "                nextnode = node.children[node.children.index(\n",
    "                    SetTrieMap.Node(data, trie=self))]\n",
    "            except ValueError:  # not found\n",
    "                nextnode = SetTrieMap.Node(data, trie=self)  # create new node\n",
    "                node.children.add(nextnode)  # add to children & sort\n",
    "            self._assign(nextnode, it, val)  # recurse\n",
    "        except StopIteration:  # end of set to add\n",
    "            node.flag_last = True\n",
    "            node.value = val\n",
    "\n",
    "    def contains(self, keyset):\n",
    "        \"\"\"Returns True iff this set-trie contains set keyset as a key.\"\"\"\n",
    "        return self._contains(self.root, iter(sorted(keyset, key=self.idx_func)))\n",
    "\n",
    "    def __contains__(self, keyset):\n",
    "        \"\"\"Returns True iff this set-trie contains set keyset as a key.\n",
    "\n",
    "        Examples:\n",
    "        This method definition allows the use of the 'in' operator.\n",
    "        example:\n",
    "\n",
    "        >>> t = SetTrieMap()\n",
    "        ... t.assign({1, 3}, 'M' )\n",
    "        ... {1, 3} in t\n",
    "        True\n",
    "        \"\"\"\n",
    "        return self.contains(keyset)\n",
    "\n",
    "    def _contains(self, node, it):\n",
    "        \"\"\"Recursive function used by self.contains().\"\"\"\n",
    "        try:\n",
    "            data = next(it)\n",
    "            try:\n",
    "                # find first child with this data\n",
    "                matchnode = node.children[node.children.index(\n",
    "                    SetTrieMap.Node(data, trie=self))]\n",
    "                return self._contains(matchnode, it)  # recurse\n",
    "            except ValueError:  # not found\n",
    "                return False\n",
    "        except StopIteration:\n",
    "            return node.flag_last\n",
    "\n",
    "    def get(self, keyset, default=None):\n",
    "        \"\"\"Return the value associated to keyset if keyset is in this\n",
    "        SetTrieMap, else default.\n",
    "        \"\"\"\n",
    "        return self._get(self.root, iter(sorted(keyset, key=self.idx_func)), default)\n",
    "\n",
    "    def _get(self, node, it, default):\n",
    "        \"\"\"Recursive function used by self.get().\"\"\"\n",
    "        try:\n",
    "            data = next(it)\n",
    "            try:\n",
    "                # find first child with this data\n",
    "                matchnode = node.children[node.children.index(\n",
    "                    SetTrieMap.Node(data, trie=self))]\n",
    "                return self._get(matchnode, it, default)  # recurse\n",
    "            except ValueError:  # not found\n",
    "                return default\n",
    "        except StopIteration:\n",
    "            return (node.value if node.flag_last else default)\n",
    "\n",
    "    def hassuperset(self, aset):\n",
    "        \"\"\"Returns True iff there is at least one key set in this SetTrieMap\n",
    "           that is the superset of set aset.\n",
    "        \"\"\"\n",
    "        return self._hassuperset(self.root, list(sorted(aset, key=self.idx_func)), 0)\n",
    "\n",
    "    def _hassuperset(self, node, setarr, idx):\n",
    "        \"\"\"Used by hassuperset().\"\"\"\n",
    "        if idx > len(setarr) - 1:\n",
    "            return True\n",
    "        found = False\n",
    "        for child in node.children:\n",
    "            # don't go to subtrees where current element cannot be\n",
    "            if child.data_hash > self.idx_func(setarr[idx]):\n",
    "                break\n",
    "            if child.data_hash == self.idx_func(setarr[idx]):\n",
    "                found = self._hassuperset(child, setarr, idx + 1)\n",
    "            else:\n",
    "                found = self._hassuperset(child, setarr, idx)\n",
    "            if found:\n",
    "                break\n",
    "        return found\n",
    "\n",
    "    def itersupersets(self, aset, mode=None):\n",
    "        \"\"\"Return an iterator over all (keyset, value) pairs from this\n",
    "           SetTrieMap for which set keyset is a superset (proper or\n",
    "           not proper) of set aset.  If mode is not None, the\n",
    "           following values are allowed:\n",
    "\n",
    "           mode='keys': return an iterator over only the keysets that\n",
    "                        are supersets of aset is returned\n",
    "           mode='values': return an iterator over only the values that\n",
    "                          are associated to keysets that are supersets\n",
    "                          of aset\n",
    "\n",
    "           If mode is neither of 'keys', 'values' or None, behavior is\n",
    "           equivalent to mode=None.\n",
    "\n",
    "        \"\"\"\n",
    "        path = []\n",
    "        return self._itersupersets(self.root, list(sorted(aset, key=self.idx_func)), 0,\n",
    "                                   path, mode)\n",
    "\n",
    "    def _itersupersets(self, node, setarr, idx, path, mode):\n",
    "        \"\"\"Used by itersupersets().\"\"\"\n",
    "        if node.data is not None:\n",
    "            path.append(node.data)\n",
    "        if node.flag_last and idx > len(setarr) - 1:\n",
    "            if mode == 'keys':\n",
    "                yield set(path)\n",
    "            elif mode == 'values':\n",
    "                yield node.value\n",
    "            else:\n",
    "                yield (set(path), node.value)\n",
    "        # we still have elements of aset to find\n",
    "        if idx <= len(setarr) - 1:\n",
    "            for child in node.children:\n",
    "                # don't go to subtrees where current element cannot be\n",
    "                if child.data_hash > self.idx_func(setarr[idx]):\n",
    "                    break\n",
    "                if child.data_hash == self.idx_func(setarr[idx]):\n",
    "                    yield from self._itersupersets(child,\n",
    "                                                   setarr,\n",
    "                                                   idx + 1,\n",
    "                                                   path,\n",
    "                                                   mode)\n",
    "                else:\n",
    "                    yield from self._itersupersets(child,\n",
    "                                                   setarr, idx,\n",
    "                                                   path, mode)\n",
    "        # no more elements to find: just traverse this subtree to get\n",
    "        # all supersets\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                yield from self._itersupersets(child, setarr,\n",
    "                                               idx, path, mode)\n",
    "        if node.data is not None:\n",
    "            path.pop()\n",
    "\n",
    "    def supersets(self, aset, mode=None):\n",
    "        \"\"\"Return a list containing pairs of (keyset, value) for which keyset\n",
    "           is superset of set aset.\n",
    "\n",
    "           Parameter mode: see documentation for itersupersets().\n",
    "        \"\"\"\n",
    "        return list(self.itersupersets(aset, mode))\n",
    "\n",
    "    def hassubset(self, aset):\n",
    "        \"\"\"Return True iff there is at least one set in this SetTrieMap that\n",
    "           is the (proper or not proper) subset of set aset.\n",
    "        \"\"\"\n",
    "        return self._hassubset(self.root, list(sorted(aset, key=self.idx_func)), 0)\n",
    "\n",
    "    def _hassubset(self, node, setarr, idx):\n",
    "        \"\"\"Used by hassubset().\"\"\"\n",
    "        if node.flag_last:\n",
    "            return True\n",
    "        if idx > len(setarr) - 1:\n",
    "            return False\n",
    "        found = False\n",
    "        try:\n",
    "            c = node.children.index(SetTrieMap.Node(setarr[idx], trie=self))\n",
    "            found = self._hassubset(node.children[c], setarr, idx + 1)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        if not found:\n",
    "            return self._hassubset(node, setarr, idx + 1)\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def itersubsets(self, aset, mode=None):\n",
    "        \"\"\"Return an iterator over pairs (keyset, value) from this SetTrieMap\n",
    "           for which keyset is (proper or not proper) subset of set aset.\n",
    "           If mode is not None, the following values are allowed:\n",
    "\n",
    "           mode='keys': return an iterator over only the keysets that\n",
    "                        are subsets of aset is returned\n",
    "\n",
    "           mode='values': return an iterator over only the values that\n",
    "                          are associated to keysets that are subsets of aset\n",
    "\n",
    "           If mode is neither of 'keys', 'values' or None, behavior is\n",
    "           equivalent to mode=None.\n",
    "        \"\"\"\n",
    "        path = []\n",
    "        return self._itersubsets(self.root, list(sorted(aset, key=self.idx_func)),\n",
    "                                 0, path, mode)\n",
    "\n",
    "    def _itersubsets(self, node, setarr, idx, path, mode):\n",
    "        \"\"\"Used by itersubsets().\"\"\"\n",
    "        if node.data is not None:\n",
    "            path.append(node.data)\n",
    "        if node.flag_last:\n",
    "            if mode == 'keys':\n",
    "                yield set(path)\n",
    "            elif mode == 'values':\n",
    "                yield node.value\n",
    "            else:\n",
    "                yield (set(path), node.value)\n",
    "        for child in node.children:\n",
    "            if idx > len(setarr) - 1:\n",
    "                break\n",
    "            if child.data_hash == self.idx_func(setarr[idx]):\n",
    "                yield from self._itersubsets(child, setarr,\n",
    "                                             idx + 1, path, mode)\n",
    "            else:\n",
    "                # advance in search set until we find child (or get to\n",
    "                # the end, or get to an element > child)\n",
    "                jdx = idx + 1\n",
    "                while jdx < len(setarr) and child.data_hash >= self.idx_func(setarr[jdx]):\n",
    "                    if child.data == setarr[jdx]:\n",
    "                        yield from self._itersubsets(child,\n",
    "                                                     setarr,\n",
    "                                                     jdx, path,\n",
    "                                                     mode)\n",
    "                        break\n",
    "                    jdx += 1\n",
    "        if node.data is not None:\n",
    "            path.pop()\n",
    "\n",
    "    def subsets(self, aset, mode=None):\n",
    "        \"\"\"Return a list of (keyset, value) pairs from this set-trie\n",
    "           for which keyset is (proper or not proper) subset of set aset.\n",
    "           Parameter mode: see documentation for itersubsets().\n",
    "        \"\"\"\n",
    "        return list(self.itersubsets(aset, mode))\n",
    "\n",
    "    def iter(self, mode=None):\n",
    "        \"\"\"Returns an iterator to all (keyset, value) pairs stored in this\n",
    "           SetTrieMap (using pre-order tree traversal).  The pairs are\n",
    "           returned sorted to their keys, which are also sorted.  If\n",
    "           mode is not None, the following values are allowed:\n",
    "\n",
    "           mode='keys': return an iterator over only the keysets that\n",
    "                        are subsets of aset\n",
    "\n",
    "           mode='values': return an iterator over only the values that\n",
    "                          are associated to keysets that are subsets\n",
    "                          of aset\n",
    "\n",
    "           If mode is neither of 'keys', 'values' or None, behavior is\n",
    "           equivalent to mode=None.\n",
    "        \"\"\"\n",
    "        path = []\n",
    "        yield from SetTrieMap._iter(self.root, path, mode)\n",
    "\n",
    "    def keys(self):\n",
    "        \"\"\"Alias for self.iter(mode='keys').\"\"\"\n",
    "        return self.iter(mode='keys')\n",
    "\n",
    "    def values(self):\n",
    "        \"\"\"Alias for self.iter(mode='values').\"\"\"\n",
    "        return self.iter(mode='values')\n",
    "\n",
    "    def items(self):\n",
    "        \"\"\"Alias for self.iter(mode=None).\"\"\"\n",
    "        return self.iter(mode=None)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Same as self.iter(mode='keys').\"\"\"\n",
    "        return self.keys()\n",
    "\n",
    "    @staticmethod\n",
    "    def _iter(node, path, mode):\n",
    "        \"\"\"Recursive function used by self.iter().\"\"\"\n",
    "        if node.data is not None:\n",
    "            path.append(node.data)\n",
    "        if node.flag_last:\n",
    "            if mode == 'keys':\n",
    "                yield set(path)\n",
    "            elif mode == 'values':\n",
    "                yield node.value\n",
    "            else:\n",
    "                yield (set(path), node.value)\n",
    "        for child in node.children:\n",
    "            yield from SetTrieMap._iter(child, path, mode)\n",
    "        if node.data is not None:\n",
    "            path.pop()\n",
    "\n",
    "    def aslist(self):\n",
    "        \"\"\"Return a list containing all the (keyset, value) pairs stored in\n",
    "           this SetTrieMap.  The pairs are returned sorted to their\n",
    "           keys, which are also sorted.\n",
    "        \"\"\"\n",
    "        return list(self.iter())\n",
    "\n",
    "    def printtree(self, tabchr=' ', tabsize=2, stream=sys.stdout):\n",
    "        \"\"\"Print a mirrored 90-degree rotation of the nodes in this SetTrieMap\n",
    "           to stream (default: sys.stdout).  Nodes marked as flag_last\n",
    "           are trailed by the '#' character.  tabchr and tabsize\n",
    "           determine the indentation: at tree level n, n*tabsize\n",
    "           tabchar characters will be used.  Associated values are\n",
    "           printed after ': ' trailing flag_last=True nodes.\n",
    "        \"\"\"\n",
    "        self._printtree(self.root, 0, tabchr, tabsize, stream)\n",
    "\n",
    "    @staticmethod\n",
    "    def _printtree(node, level, tabchr, tabsize, stream):\n",
    "        \"\"\"Used by self.printTree(), recursive preorder traverse and printing\n",
    "           of trie node\n",
    "        \"\"\"\n",
    "        print((str(node.data).rjust(len(repr(node.data)) + level * tabsize,\n",
    "                                    tabchr) + (': {}'.format(repr(node.value)) if\n",
    "                                               node.flag_last else '')),\n",
    "              file=stream)\n",
    "        for child in node.children:\n",
    "            SetTrieMap._printtree(child, level + 1, tabchr, tabsize, stream)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Returns str(self.aslist()).\"\"\"\n",
    "        return str(self.aslist())\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Returns str(self.aslist()).\"\"\"\n",
    "        return str(self.aslist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90e279-6333-4d24-a049-30ca0a131a7e",
   "metadata": {},
   "source": [
    "... and the equivalent class for mercury.dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dcfe68-1308-4b4d-a051-349646f98236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import settrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd56a352-65a4-47d4-a089-5e57e7d620f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settrie.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef6e40-9a09-4fbe-abfc-f651381db23c",
   "metadata": {},
   "source": [
    "We instance one object of each `stm` for the pure python implementation and `st` from mercury dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd702d3a-1ddd-4bb7-aef2-fdd3ce5d4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = SetTrieMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4a62fa-43d2-4f70-ad3f-0fc470ef179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = settrie.SetTrie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d97273-d0a9-4e97-8af7-f118c3f145cf",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "This dataset is a folder containing lots of text documents created randomly by composing the syllables:\n",
    "\n",
    "`['bla' , 'co', 'doe', 'fi', 'gru', 'ho', 'je', 'ko', 'le', 'mu', 'no', 'pre', 're', 'sha', 'tri', 'voe', 'wha', 'ye', 'zu']`\n",
    "\n",
    "The original datasets where in the size of hundredths of thousands of documents, the pure python implementation could not handle those sizes and it was reduced to 50,000.\n",
    "\n",
    "With 50,000 documents the mercury dynamics implementation gave improved performance of around x200 to x300 and x20 in RAM size for the harder queries.\n",
    "\n",
    "This dataset is a small sample (1,500 documents) and the gains are around x100 to x150 in the hardest queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8be814-a59c-454b-9215-fd6ce0c5a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "!if [ ! -d ./data ]; then tar -xf settrie_data.tar.gz; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc4d87-36f0-4ff4-bc00-9c7d88bdf8aa",
   "metadata": {},
   "source": [
    "## Comparing loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed98530-dab1-4ef7-811a-df0d931934d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d1137-f68b-4657-9ab2-4935008d4ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a7c5cf8-bd1e-4753-96db-033b181e3ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy assign time is 0.289 seconds\n"
     ]
    }
   ],
   "source": [
    "def dummy_assign(set, key):\n",
    "    pass\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1500):\n",
    "    fn = 'data/%i.txt' % (i + 1)\n",
    "    with open(fn) as f:\n",
    "        txt = f.readlines()[0].rstrip('\\n')\n",
    "        \n",
    "        dummy_assign(set(txt.split(' ')), fn)\n",
    "        \n",
    "dummy_time = time.time() - start_time\n",
    "        \n",
    "print(\"Dummy assign time is %0.3f seconds\" % (dummy_time, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de96447b-8a10-4425-b28c-c6e73c240dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time - dummy_time in 15.269 seconds\n",
      "RAM increase in 710.7Mb\n"
     ]
    }
   ],
   "source": [
    "start_ram = get_process_memory()\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1500):\n",
    "    fn = 'data/%i.txt' % (i + 1)\n",
    "    with open(fn) as f:\n",
    "        txt = f.readlines()[0].rstrip('\\n')\n",
    "        \n",
    "        stm.assign(set(txt.split(' ')), fn)\n",
    "        \n",
    "print(\"Time - dummy_time in %0.3f seconds\" % (time.time() - start_time - dummy_time, ))\n",
    "print(\"RAM increase in %0.1fMb\" % ((get_process_memory() - start_ram)/(1024*1024), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e74004d-b413-4320-9035-7d95846c97c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time - dummy_time in 1.066 seconds\n",
      "RAM increase in 45.5Mb\n"
     ]
    }
   ],
   "source": [
    "start_ram = get_process_memory()\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1500):\n",
    "    fn = 'data/%i.txt' % (i + 1)\n",
    "    with open(fn) as f:\n",
    "        txt = f.readlines()[0].rstrip('\\n')\n",
    "        \n",
    "        st.insert(set(txt.split(' ')), fn)\n",
    "        \n",
    "print(\"Time - dummy_time in %0.3f seconds\" % (time.time() - start_time - dummy_time, ))\n",
    "print(\"RAM increase in %0.1fMb\" % ((get_process_memory() - start_ram)/(1024*1024), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a33c5-0fb2-4386-a804-0cbe1257f421",
   "metadata": {},
   "source": [
    "## Comparing finding exact (whole document) matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e477c9b-22f1-48c5-ad38-498678225f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stm_find(query):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(stm.get(query))\n",
    "                \n",
    "    print(\"Done in %0.3f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b673d4-4501-416e-80c5-983f9ae4c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_find(query):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(st.find(query))\n",
    "                \n",
    "    print(\"Done in %0.3f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62805808-b598-4717-88fb-cacde78b73a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85de14ff-3c3e-4b4d-9293-0a9fc0d9ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/712.txt\n",
      "Done in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_find({'doecotri', 'cogruyedoe', 'yeho', 'bla', 'shazudoe', 'je', 'bla', 'pre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d80a9e-2eaf-4b15-9136-24068b27cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/712.txt\n",
      "Done in 0.000 seconds\n"
     ]
    }
   ],
   "source": [
    "st_find({'doecotri', 'cogruyedoe', 'yeho', 'bla', 'shazudoe', 'je', 'bla', 'pre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f735a3-dc30-4591-b156-58870f0f92df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f24c9bdf-7c85-4a8f-b8bd-4a539e95399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/777.txt\n",
      "Done in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_find({'tri', 'mupre', 'le', 'gru', 'kozugru', 'reye', 'no', 'whaprerele', 'tri', 'reblazu', 'noko', 'yewhatrihobla', 'novoe', 'jeletrifivoe', 'co'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad0efb9d-5d8e-41c0-acdb-674c180864a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/777.txt\n",
      "Done in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "st_find({'tri', 'mupre', 'le', 'gru', 'kozugru', 'reye', 'no', 'whaprerele', 'tri', 'reblazu', 'noko', 'yewhatrihobla', 'novoe', 'jeletrifivoe', 'co'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce785ab0-a00a-42cb-a9cf-9482d10d7474",
   "metadata": {},
   "source": [
    "## Comparing finding partial (all words in any document) matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea4322c9-a3a3-4315-b194-28c7fcd53720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stm_super(query, verbose = False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for _, key in stm.supersets(query):\n",
    "        ret.append(key)\n",
    "        \n",
    "    ret.sort()\n",
    "    \n",
    "    if verbose:\n",
    "        print(ret)\n",
    "    else:\n",
    "        print(len(ret), 'document(s) found.')\n",
    "        \n",
    "    print(\"Done in %0.3f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe0f13-0bcc-4eb8-aaf0-f111e83a7769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f60dc33-b3d9-447f-85fc-19e3d1a9dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_super(query, verbose = False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for key in st.supersets(query):\n",
    "        ret.append(key)\n",
    "        \n",
    "    ret.sort()\n",
    "    \n",
    "    if verbose:\n",
    "        print(ret)\n",
    "    else:\n",
    "        print(len(ret), 'document(s) found.')\n",
    "        \n",
    "    print(\"Done in %0.3f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a3c8f-7cbb-4ef3-9b0a-89429f2e0a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d07c5460-e9ab-495f-9255-06c98b781c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/1013.txt']\n",
      "Done in 0.207 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_super({'pre', 'le', 'whamu', 'tri', 'zulenoko'}, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1838b687-b5db-4b24-a1b1-8372c2a45d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/1013.txt']\n",
      "Done in 0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "st_super({'pre', 'le', 'whamu', 'tri', 'zulenoko'}, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aeaf7b-7dcd-4a21-9a2c-f293411c863d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30e255a9-f837-4564-949a-7df56b10288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/1092.txt', 'data/1400.txt', 'data/1446.txt', 'data/202.txt', 'data/314.txt', 'data/475.txt', 'data/593.txt', 'data/64.txt', 'data/759.txt', 'data/764.txt', 'data/796.txt', 'data/805.txt', 'data/891.txt']\n",
      "Done in 0.726 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_super({'whagru', 'yewhako', 'blavoe'}, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8a34a27-6ecf-47bc-8d39-c80f74d90799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/1092.txt', 'data/1400.txt', 'data/1446.txt', 'data/202.txt', 'data/314.txt', 'data/475.txt', 'data/593.txt', 'data/64.txt', 'data/759.txt', 'data/764.txt', 'data/796.txt', 'data/805.txt', 'data/891.txt']\n",
      "Done in 0.005 seconds\n"
     ]
    }
   ],
   "source": [
    "st_super({'whagru', 'yewhako', 'blavoe'}, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82daab-62a9-4d8a-a148-68e78abff2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89b451b2-f88b-4c50-83cd-7561ec172807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 document(s) found.\n",
      "Done in 0.721 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_super({'whagru', 'yewhako', 'blavoe'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b06c7d-3ee3-4296-bcb2-6e2116258f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 document(s) found.\n",
      "Done in 0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "st_super({'whagru', 'yewhako', 'blavoe'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c512cb3-19bd-48b9-b7dc-e05c33fcc921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39ba8e2e-4d39-4655-b56b-bfd5d5560091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440 document(s) found.\n",
      "Done in 3.360 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_super({'wha'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4052a9-c68f-42f8-8b34-a01811ac7a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440 document(s) found.\n",
      "Done in 0.010 seconds\n"
     ]
    }
   ],
   "source": [
    "st_super({'wha'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f0cec-5823-4691-98bd-ec02d8d3d3bc",
   "metadata": {},
   "source": [
    "## Comparing finding subset (the whole document can be written with a set of words) matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e251bad-5ffa-44ef-9f99-6aa10059d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stm_sub(query, verbose = False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for _, key in stm.subsets(query):\n",
    "        ret.append(key)\n",
    "        \n",
    "    ret.sort()\n",
    "    \n",
    "    if verbose:\n",
    "        print(ret)\n",
    "    else:\n",
    "        print(len(ret), 'document(s) found.')\n",
    "        \n",
    "    print(\"Done in %0.3f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58cf64de-bdc2-4ba0-ba92-d970132a01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_sub(query, verbose = False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for key in st.subsets(query):\n",
    "        ret.append(key)\n",
    "        \n",
    "    ret.sort()\n",
    "    \n",
    "    if verbose:\n",
    "        print(ret)\n",
    "    else:\n",
    "        print(len(ret), 'document(s) found.')\n",
    "        \n",
    "    print(\"Done in %0.3f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff4376-358d-455b-b7f8-877a0d0e7e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "761340a0-3947-455d-b517-98f978adfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {'doecotri', 'cogruyedoe', 'yeho', 'bla', 'shazudoe', 'je', 'bla', 'pre'}\n",
    "vocabulary.update(['tri', 'mupre', 'le', 'gru', 'kozugru', 'reye', 'no', 'whaprerele', 'tri', 'reblazu', 'noko', 'yewhatrihobla', 'novoe', 'jeletrifivoe', 'co'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "366e0ef0-ce28-470c-9d84-80be030b2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/712.txt', 'data/777.txt']\n",
      "Done in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_sub(vocabulary, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86481300-1f19-4f91-b606-995e93887d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/712.txt', 'data/777.txt']\n",
      "Done in 0.000 seconds\n"
     ]
    }
   ],
   "source": [
    "st_sub(vocabulary, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ba2065b-bb9f-4617-a091-12d8a02e255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.update(['wha', 'jehovoe', 'koyegru', 'mukoyegru', 'hono', 'gru', 'fizugru', 'lenomuwha', 'kozuwhaco', 'ho', 'pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb799098-4dac-4830-a910-64113590ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.update(['trire', 'co', 'whavoe', 'noblaretripre', 'no', 'yezushadoele', 'blale', 'hodoeretriwhaye', 'le', 'shadoe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71df1af2-e8fc-49d5-b511-83455207495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.update(['jenoye', 'zumuhotrinofi', 'ko', 'ho', 'voebla', 'jezukofibla', 'blazu', 'lehowha', 'le', 'jezublahoko', 'kofizu', 'wha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b114286-c121-4d7f-b34b-b69fe68b1f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/218.txt', 'data/274.txt', 'data/362.txt', 'data/712.txt', 'data/777.txt']\n",
      "Done in 0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_sub(vocabulary, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69ad6647-3edc-4949-9184-d8ce07dcf034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/218.txt', 'data/274.txt', 'data/362.txt', 'data/712.txt', 'data/777.txt']\n",
      "Done in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "st_sub(vocabulary, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfaeee0-cb83-47dc-bd71-d6c534b4d982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee20f797-eab5-480d-93fb-343bbacf4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1200):\n",
    "    fn = 'data/%i.txt' % (i + 1)\n",
    "    with open(fn) as f:\n",
    "        txt = f.readlines()[0].rstrip('\\n')\n",
    "        \n",
    "        vocabulary.update(txt.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a087fe7-f7d2-4ac8-b3c6-bf0b335faf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "921a6b2c-8f6c-40ad-969d-cb59bbe0e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 document(s) found.\n",
      "Done in 111.348 seconds\n"
     ]
    }
   ],
   "source": [
    "stm_sub(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a256823-6282-4440-853a-2deaff67baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 document(s) found.\n",
      "Done in 0.556 seconds\n"
     ]
    }
   ],
   "source": [
    "st_sub(vocabulary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
